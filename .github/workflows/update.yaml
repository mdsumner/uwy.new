name: Update Underway Data

on:
  schedule:
    - cron: '0 */2 * * *'  # Every 2 hours (12 runs/day vs 48)
  workflow_dispatch:

concurrency:
  group: underway-update
  cancel-in-progress: false  # Let running job finish, don't corrupt data

permissions:
  contents: write

env:
  GDAL_IMAGE: ghcr.io/osgeo/gdal:ubuntu-full-3.12.1
  RELEASE_TAG: v0.0.1
  PARQUET_FILE: nuyina_underway.parquet
  WFS_BASE: https://data.aad.gov.au/geoserver/underway/ows

jobs:
  update:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Get current max datetime from release
        id: current
        run: |
          # Download just enough of the parquet to read metadata (or fail fast if no release)
          RELEASE_URL="https://github.com/${{ github.repository }}/releases/download/${{ env.RELEASE_TAG }}/${{ env.PARQUET_FILE }}"
          
          if curl -fsSL --head "$RELEASE_URL" > /dev/null 2>&1; then
            echo "exists=true" >> $GITHUB_OUTPUT
            # We'll get the actual max datetime after downloading
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "No existing release - will do full fetch"
          fi

      - name: Check WFS for latest record
        id: check
        run: |
          # Lightweight query: just get the single most recent record
          LATEST=$(curl -sf "${{ env.WFS_BASE }}?service=WFS&version=2.0.0&request=GetFeature&typeName=underway:nuyina_underway&count=1&sortBy=datetime+D&outputFormat=application/json" \
            | jq -r '.features[0].properties.datetime // empty' 2>/dev/null || echo "")
          
          if [[ -z "$LATEST" ]]; then
            echo "WFS query failed or returned no data"
            echo "has_data=false" >> $GITHUB_OUTPUT
          else
            echo "WFS latest: $LATEST"
            echo "has_data=true" >> $GITHUB_OUTPUT
            echo "latest=$LATEST" >> $GITHUB_OUTPUT
          fi

      - name: Checkout
        if: steps.check.outputs.has_data == 'true'
        uses: actions/checkout@v4

      - name: Download existing parquet from release
        id: download
        if: steps.check.outputs.has_data == 'true' && steps.current.outputs.exists == 'true'
        run: |
          mkdir -p data
          curl -fsSL -o "data/${{ env.PARQUET_FILE }}" \
            "https://github.com/${{ github.repository }}/releases/download/${{ env.RELEASE_TAG }}/${{ env.PARQUET_FILE }}"
          echo "Downloaded existing parquet: $(stat -c%s "data/${{ env.PARQUET_FILE }}") bytes"

      - name: Get max datetime from existing data
        id: maxdt
        if: steps.download.outcome == 'success'
        run: |
          # Extract max datetime using SQL
          MAX_DT=$(docker run --rm -v "$PWD/data:/data" ${{ env.GDAL_IMAGE }} \
            ogrinfo -sql "SELECT MAX(datetime) as max_dt FROM nuyina_underway" \
            "/data/${{ env.PARQUET_FILE }}" 2>/dev/null | \
            grep -oE '[0-9]{4}[-/][0-9]{2}[-/][0-9]{2}[T ][0-9]{2}:[0-9]{2}:[0-9]{2}' | \
            head -1 || echo "")

          if [[ -n "$MAX_DT" ]]; then
            MAX_DT="${MAX_DT//\//-}"
            echo "datetime=$MAX_DT" >> $GITHUB_OUTPUT
            echo "Current max datetime: $MAX_DT"
            
            # Compare with WFS latest - if same, skip
            WFS_LATEST="${{ steps.check.outputs.latest }}"
            # Normalize for comparison (remove fractional seconds, etc)
            MAX_DT_NORM=$(echo "$MAX_DT" | cut -c1-19)
            WFS_NORM=$(echo "$WFS_LATEST" | cut -c1-19)
            
            if [[ "$MAX_DT_NORM" == "$WFS_NORM" ]] || [[ "$MAX_DT" > "$WFS_LATEST" ]]; then
              echo "No new data (current: $MAX_DT_NORM, WFS: $WFS_NORM)"
              echo "needs_update=false" >> $GITHUB_OUTPUT
            else
              echo "New data available"
              echo "needs_update=true" >> $GITHUB_OUTPUT
            fi
          else
            echo "Could not extract max datetime, will fetch"
            echo "needs_update=true" >> $GITHUB_OUTPUT
          fi

      - name: Fetch new data from WFS
        id: fetch
        if: steps.check.outputs.has_data == 'true' && (steps.current.outputs.exists != 'true' || steps.maxdt.outputs.needs_update == 'true')
        run: |
          WFS_URL="WFS:https://data.aad.gov.au/geoserver/ows?service=wfs&version=2.0.0&request=GetCapabilities"
          LAYER="underway:nuyina_underway"

          mkdir -p data/tmp

          if [[ -n "${{ steps.maxdt.outputs.datetime }}" ]]; then
            echo "Fetching incremental data since ${{ steps.maxdt.outputs.datetime }}..."

            docker run --rm -v "$PWD/data:/data" ${{ env.GDAL_IMAGE }} \
              ogr2ogr -f Parquet "/data/tmp/new_records.parquet" \
              "$WFS_URL" "$LAYER" \
              -where "datetime > '${{ steps.maxdt.outputs.datetime }}'" \
              -lco COMPRESSION=ZSTD \
              -progress 2>&1 || true

            if [[ -f "data/tmp/new_records.parquet" ]] && [[ -s "data/tmp/new_records.parquet" ]]; then
              NEW_COUNT=$(docker run --rm -v "$PWD/data:/data" ${{ env.GDAL_IMAGE }} \
                ogrinfo -sql "SELECT COUNT(*) as cnt FROM new_records" "/data/tmp/new_records.parquet" 2>/dev/null | \
                grep -oE 'cnt \(Integer\) = [0-9]+' | grep -oE '[0-9]+' || echo "0")

              echo "Found $NEW_COUNT new records"
              echo "new_records=$NEW_COUNT" >> $GITHUB_OUTPUT
              echo "mode=incremental" >> $GITHUB_OUTPUT
            else
              echo "No new records found"
              echo "new_records=0" >> $GITHUB_OUTPUT
              echo "mode=none" >> $GITHUB_OUTPUT
            fi
          else
            echo "Fetching full dataset..."
            docker run --rm -v "$PWD/data:/data" ${{ env.GDAL_IMAGE }} \
              ogr2ogr -f Parquet "/data/tmp/full.parquet" \
              "$WFS_URL" "$LAYER" \
              -lco COMPRESSION=ZSTD \
              -progress

            echo "mode=full" >> $GITHUB_OUTPUT
          fi

      - name: Merge and validate data
        id: merge
        if: steps.fetch.outcome == 'success'
        run: |
          set -e

          if [[ "${{ steps.fetch.outputs.mode }}" == "full" ]]; then
            if [[ -f "data/tmp/full.parquet" ]] && [[ -s "data/tmp/full.parquet" ]]; then
              mv "data/tmp/full.parquet" "data/${{ env.PARQUET_FILE }}"
              echo "status=success" >> $GITHUB_OUTPUT
            else
              echo "ERROR: Full fetch produced no data"
              echo "status=failed" >> $GITHUB_OUTPUT
              exit 1
            fi

          elif [[ "${{ steps.fetch.outputs.mode }}" == "incremental" ]] && [[ "${{ steps.fetch.outputs.new_records }}" != "0" ]]; then
            echo "Merging incremental data..."

            cp "data/${{ env.PARQUET_FILE }}" "data/${{ env.PARQUET_FILE }}.bak"

            docker run --rm -v "$PWD/data:/data" ${{ env.GDAL_IMAGE }} \
              ogrmerge.py -f Parquet \
              -o "/data/tmp/merged.parquet" \
              "/data/${{ env.PARQUET_FILE }}" \
              "/data/tmp/new_records.parquet" \
              -single -lco COMPRESSION=ZSTD

            if [[ -f "data/tmp/merged.parquet" ]] && [[ -s "data/tmp/merged.parquet" ]]; then
              MERGED_COUNT=$(docker run --rm -v "$PWD/data:/data" ${{ env.GDAL_IMAGE }} \
                ogrinfo -sql "SELECT COUNT(*) as cnt FROM merged" "/data/tmp/merged.parquet" 2>/dev/null | \
                grep -oE '[0-9]+' | tail -1 || echo "0")

              if [[ "$MERGED_COUNT" -gt 0 ]]; then
                mv "data/tmp/merged.parquet" "data/${{ env.PARQUET_FILE }}"
                rm -f "data/${{ env.PARQUET_FILE }}.bak"
                echo "Merged successfully. Total records: $MERGED_COUNT"
                echo "status=success" >> $GITHUB_OUTPUT
              else
                echo "ERROR: Merged file validation failed, restoring backup"
                mv "data/${{ env.PARQUET_FILE }}.bak" "data/${{ env.PARQUET_FILE }}"
                echo "status=failed" >> $GITHUB_OUTPUT
                exit 1
              fi
            else
              echo "ERROR: Merge failed, restoring backup"
              mv "data/${{ env.PARQUET_FILE }}.bak" "data/${{ env.PARQUET_FILE }}"
              echo "status=failed" >> $GITHUB_OUTPUT
              exit 1
            fi

          else
            echo "No changes to make"
            echo "status=unchanged" >> $GITHUB_OUTPUT
          fi

          rm -rf data/tmp

      - name: Get final stats
        if: steps.merge.outputs.status == 'success'
        run: |
          echo "=== Final Data Statistics ==="
          docker run --rm -v "$PWD/data:/data" ${{ env.GDAL_IMAGE }} \
            ogrinfo -al -so "/data/${{ env.PARQUET_FILE }}" 2>/dev/null | head -50

          echo ""
          echo "File size: $(stat -c%s "data/${{ env.PARQUET_FILE }}") bytes"

      - name: Upload to release
        if: steps.merge.outputs.status == 'success'
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ env.RELEASE_TAG }}
          files: data/${{ env.PARQUET_FILE }}
          fail_on_unmatched_files: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
